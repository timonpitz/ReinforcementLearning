{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install gym\n",
    "#!pip install matplotlib\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spaces erstellen um stetige Werte für Position und Geschwindigkeit in diskrete Werte einzuordnen\n",
    "pos_buckets = np.linspace(-1.2, 0.6, 20)\n",
    "vel_buckets = np.linspace(-0.07, 0.07, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Status des Objektes wird durch Position und Geschwindigkeit in diskreten Werten zurueckgegeben\n",
    "def toDiscreteStates(obs):\n",
    "    pos, vel = obs\n",
    "    \n",
    "    #Stetige Werte werden in die oben definierten Buckets eingeordnet\n",
    "    pos_disc = np.digitize(pos, pos_buckets)\n",
    "    vel_disc = np.digitize(vel, vel_buckets)\n",
    "    \n",
    "    return(pos_disc, vel_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion, um die naechste Aktion herauszufinden\n",
    "def get_action(Q, obs, actions=[0,1,2]):\n",
    "    #Epsilon-Greedy-Algorithmus\n",
    "    #Mit einer Wahrscheinlichtkeit von Epsilon wird eine zufällige Aktion ausgeführt\n",
    "    if np.random.random() < eps:\n",
    "        action = np.random.choice([0,1,2])\n",
    "    #Sonst wird die Aktion ausgewählt, die wahrscheinlich die beste Belohnung ergibt\n",
    "    else: \n",
    "        state = toDiscreteStates(obs)\n",
    "        values = []\n",
    "        for a in actions:\n",
    "            values.append(Q[state, a])\n",
    "\n",
    "        action = np.argmax(values)\n",
    "    \n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCar-v0') #Umgebung erstellen\n",
    "env._max_episode_steps = 1000 #Maximale Steps bis das Spiel abbricht, wenn es nicht geschafft wird\n",
    "n_games = 50000 #Anzahl der Trainingsdurchläufe\n",
    "alpha = 0.1 \n",
    "gamma = 0.99\n",
    "eps = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-Dimensionale Liste mit allen moeglichen Status\n",
    "states = []\n",
    "for pos in range(21):\n",
    "    for vel in range(21):\n",
    "        states.append((pos,vel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q-Tabelle als Dictionary der Form 441x3 mit allen Kombinationen aus Position & Aktion\n",
    "Q = {}\n",
    "for state in states:\n",
    "    for action in [0,1,2]:\n",
    "        Q[state, action] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion um Q-Tabelle lokal abzuspeichern\n",
    "def saveQ():\n",
    "    with open('obj/Qtable.pkl', 'wb') as f:\n",
    "        pickle.dump(Q, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktion um lokale Q-Tabelle zu laden und so an vorheriges Lernen anknuepfen zu koennen\n",
    "def loadQ(obs, action, reward, new_obs_new_action):\n",
    "    with open('obj/Qtable.pkl', 'rb') as f:\n",
    "        pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateQ_SARSA(obs, action, reward, new_obs, new_action):\n",
    "    state = toDiscreteStates(obs)\n",
    "    new_state = toDiscreteStates(new_obs)\n",
    "    Q[state, action] = Q[state, action] + alpha*(reward + gamma*Q[new_state, new_action] - Q[state, action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spielt mit der gespeicherten Q-Tabelle 10 Spiele um den Lernfortschritt darzustellen\n",
    "def show_results():\n",
    "    Q = loadQ()\n",
    "    new_eps = 0.01\n",
    "    for i in range(10):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        while not done:\n",
    "            if np.random.random() < new_eps:\n",
    "                action = np.random.choice ([0,1,2])\n",
    "            else:\n",
    "                action = max_action(Q, obs)\n",
    "                \n",
    "            new_obs, reward, done, info = env.step(action)\n",
    "            new_action = max_action(Q, new_obs)\n",
    "            updateQ(obs, action, reward, new_obs, new_action)\n",
    "            obs = new_obs\n",
    "            env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  100 score  -1000.0 eps  0.995999999999996\n",
      "episode  200 score  -1000.0 eps  0.991999999999992\n",
      "episode  300 score  -1000.0 eps  0.987999999999988\n",
      "episode  400 score  -1000.0 eps  0.983999999999984\n",
      "episode  500 score  -1000.0 eps  0.97999999999998\n",
      "episode  600 score  -1000.0 eps  0.975999999999976\n",
      "episode  700 score  -1000.0 eps  0.971999999999972\n",
      "episode  800 score  -1000.0 eps  0.967999999999968\n",
      "episode  900 score  -1000.0 eps  0.963999999999964\n",
      "episode  1000 score  -1000.0 eps  0.95999999999996\n",
      "episode  1100 score  -1000.0 eps  0.955999999999956\n",
      "episode  1200 score  -1000.0 eps  0.951999999999952\n",
      "episode  1300 score  -1000.0 eps  0.947999999999948\n",
      "episode  1400 score  -1000.0 eps  0.943999999999944\n",
      "episode  1500 score  -1000.0 eps  0.93999999999994\n",
      "episode  1600 score  -1000.0 eps  0.935999999999936\n",
      "episode  1700 score  -1000.0 eps  0.931999999999932\n",
      "episode  1800 score  -1000.0 eps  0.927999999999928\n",
      "episode  1900 score  -1000.0 eps  0.923999999999924\n",
      "episode  2000 score  -855.0 eps  0.91999999999992\n",
      "episode  2100 score  -1000.0 eps  0.915999999999916\n",
      "episode  2200 score  -1000.0 eps  0.911999999999912\n",
      "episode  2300 score  -1000.0 eps  0.907999999999908\n",
      "episode  2400 score  -1000.0 eps  0.903999999999904\n",
      "episode  2500 score  -1000.0 eps  0.8999999999999\n",
      "episode  2600 score  -1000.0 eps  0.895999999999896\n",
      "episode  2700 score  -929.0 eps  0.891999999999892\n",
      "episode  2800 score  -1000.0 eps  0.887999999999888\n",
      "episode  2900 score  -1000.0 eps  0.883999999999884\n",
      "episode  3000 score  -1000.0 eps  0.87999999999988\n",
      "episode  3100 score  -1000.0 eps  0.875999999999876\n",
      "episode  3200 score  -1000.0 eps  0.871999999999872\n",
      "episode  3300 score  -1000.0 eps  0.867999999999868\n",
      "episode  3400 score  -1000.0 eps  0.863999999999864\n",
      "episode  3500 score  -1000.0 eps  0.85999999999986\n",
      "episode  3600 score  -1000.0 eps  0.855999999999856\n",
      "episode  3700 score  -791.0 eps  0.851999999999852\n",
      "episode  3800 score  -923.0 eps  0.847999999999848\n",
      "episode  3900 score  -808.0 eps  0.843999999999844\n",
      "episode  4000 score  -1000.0 eps  0.83999999999984\n",
      "episode  4100 score  -870.0 eps  0.835999999999836\n",
      "episode  4200 score  -1000.0 eps  0.831999999999832\n",
      "episode  4300 score  -545.0 eps  0.827999999999828\n",
      "episode  4400 score  -833.0 eps  0.823999999999824\n",
      "episode  4500 score  -524.0 eps  0.81999999999982\n",
      "episode  4600 score  -1000.0 eps  0.815999999999816\n",
      "episode  4700 score  -1000.0 eps  0.811999999999812\n",
      "episode  4800 score  -527.0 eps  0.807999999999808\n",
      "episode  4900 score  -624.0 eps  0.803999999999804\n",
      "episode  5000 score  -998.0 eps  0.7999999999998\n",
      "episode  5100 score  -855.0 eps  0.795999999999796\n",
      "episode  5200 score  -1000.0 eps  0.791999999999792\n",
      "episode  5300 score  -492.0 eps  0.787999999999788\n",
      "episode  5400 score  -526.0 eps  0.783999999999784\n",
      "episode  5500 score  -969.0 eps  0.77999999999978\n",
      "episode  5600 score  -653.0 eps  0.775999999999776\n",
      "episode  5700 score  -899.0 eps  0.771999999999772\n",
      "episode  5800 score  -826.0 eps  0.767999999999768\n",
      "episode  5900 score  -848.0 eps  0.763999999999764\n",
      "episode  6000 score  -1000.0 eps  0.75999999999976\n",
      "episode  6100 score  -709.0 eps  0.755999999999756\n",
      "episode  6200 score  -1000.0 eps  0.751999999999752\n",
      "episode  6300 score  -1000.0 eps  0.747999999999748\n",
      "episode  6400 score  -603.0 eps  0.743999999999744\n",
      "episode  6500 score  -1000.0 eps  0.73999999999974\n",
      "episode  6600 score  -923.0 eps  0.735999999999736\n",
      "episode  6700 score  -711.0 eps  0.731999999999732\n",
      "episode  6800 score  -1000.0 eps  0.727999999999728\n",
      "episode  6900 score  -647.0 eps  0.723999999999724\n",
      "episode  7000 score  -1000.0 eps  0.71999999999972\n",
      "episode  7100 score  -414.0 eps  0.715999999999716\n",
      "episode  7200 score  -1000.0 eps  0.711999999999712\n",
      "episode  7300 score  -532.0 eps  0.707999999999708\n",
      "episode  7400 score  -410.0 eps  0.703999999999704\n",
      "episode  7500 score  -629.0 eps  0.6999999999997\n",
      "episode  7600 score  -407.0 eps  0.695999999999696\n",
      "episode  7700 score  -1000.0 eps  0.691999999999692\n",
      "episode  7800 score  -531.0 eps  0.687999999999688\n",
      "episode  7900 score  -1000.0 eps  0.683999999999684\n",
      "episode  8000 score  -505.0 eps  0.67999999999968\n",
      "episode  8100 score  -376.0 eps  0.675999999999676\n",
      "episode  8200 score  -1000.0 eps  0.671999999999672\n",
      "episode  8300 score  -601.0 eps  0.667999999999668\n",
      "episode  8400 score  -378.0 eps  0.663999999999664\n",
      "episode  8500 score  -858.0 eps  0.65999999999966\n",
      "episode  8600 score  -783.0 eps  0.655999999999656\n",
      "episode  8700 score  -334.0 eps  0.651999999999652\n",
      "episode  8800 score  -768.0 eps  0.647999999999648\n",
      "episode  8900 score  -320.0 eps  0.643999999999644\n",
      "episode  9000 score  -392.0 eps  0.63999999999964\n",
      "episode  9100 score  -424.0 eps  0.635999999999636\n",
      "episode  9200 score  -432.0 eps  0.631999999999632\n",
      "episode  9300 score  -615.0 eps  0.627999999999628\n",
      "episode  9400 score  -621.0 eps  0.623999999999624\n",
      "episode  9500 score  -828.0 eps  0.61999999999962\n",
      "episode  9600 score  -465.0 eps  0.615999999999616\n",
      "episode  9700 score  -602.0 eps  0.611999999999612\n",
      "episode  9800 score  -453.0 eps  0.607999999999608\n",
      "episode  9900 score  -334.0 eps  0.603999999999604\n",
      "episode  10000 score  -438.0 eps  0.5999999999996\n",
      "episode  10100 score  -348.0 eps  0.595999999999596\n",
      "episode  10200 score  -496.0 eps  0.591999999999592\n",
      "episode  10300 score  -288.0 eps  0.587999999999588\n",
      "episode  10400 score  -399.0 eps  0.583999999999584\n",
      "episode  10500 score  -528.0 eps  0.57999999999958\n",
      "episode  10600 score  -337.0 eps  0.575999999999576\n",
      "episode  10700 score  -334.0 eps  0.571999999999572\n",
      "episode  10800 score  -462.0 eps  0.567999999999568\n",
      "episode  10900 score  -362.0 eps  0.563999999999564\n",
      "episode  11000 score  -467.0 eps  0.55999999999956\n",
      "episode  11100 score  -429.0 eps  0.555999999999556\n",
      "episode  11200 score  -413.0 eps  0.551999999999552\n",
      "episode  11300 score  -520.0 eps  0.547999999999548\n",
      "episode  11400 score  -586.0 eps  0.543999999999544\n",
      "episode  11500 score  -294.0 eps  0.53999999999954\n",
      "episode  11600 score  -262.0 eps  0.535999999999536\n",
      "episode  11700 score  -394.0 eps  0.531999999999532\n",
      "episode  11800 score  -236.0 eps  0.527999999999528\n",
      "episode  11900 score  -427.0 eps  0.523999999999524\n",
      "episode  12000 score  -378.0 eps  0.51999999999952\n",
      "episode  12100 score  -237.0 eps  0.515999999999516\n",
      "episode  12200 score  -495.0 eps  0.511999999999512\n",
      "episode  12300 score  -327.0 eps  0.507999999999508\n",
      "episode  12400 score  -281.0 eps  0.503999999999504\n",
      "episode  12500 score  -260.0 eps  0.4999999999995\n",
      "episode  12600 score  -402.0 eps  0.49599999999950156\n",
      "episode  12700 score  -486.0 eps  0.4919999999995031\n",
      "episode  12800 score  -241.0 eps  0.48799999999950466\n",
      "episode  12900 score  -467.0 eps  0.4839999999995062\n",
      "episode  13000 score  -305.0 eps  0.47999999999950776\n",
      "episode  13100 score  -167.0 eps  0.4759999999995093\n",
      "episode  13200 score  -348.0 eps  0.47199999999951087\n",
      "episode  13300 score  -249.0 eps  0.4679999999995124\n",
      "episode  13400 score  -618.0 eps  0.46399999999951397\n",
      "episode  13500 score  -336.0 eps  0.4599999999995155\n",
      "episode  13600 score  -247.0 eps  0.45599999999951707\n",
      "episode  13700 score  -245.0 eps  0.4519999999995186\n",
      "episode  13800 score  -334.0 eps  0.44799999999952017\n",
      "episode  13900 score  -175.0 eps  0.4439999999995217\n",
      "episode  14000 score  -605.0 eps  0.4399999999995233\n",
      "episode  14100 score  -461.0 eps  0.4359999999995248\n",
      "episode  14200 score  -246.0 eps  0.4319999999995264\n",
      "episode  14300 score  -159.0 eps  0.4279999999995279\n",
      "episode  14400 score  -170.0 eps  0.4239999999995295\n",
      "episode  14500 score  -162.0 eps  0.419999999999531\n",
      "episode  14600 score  -266.0 eps  0.4159999999995326\n",
      "episode  14700 score  -234.0 eps  0.41199999999953413\n",
      "episode  14800 score  -229.0 eps  0.4079999999995357\n",
      "episode  14900 score  -249.0 eps  0.40399999999953723\n",
      "episode  15000 score  -255.0 eps  0.3999999999995388\n",
      "episode  15100 score  -374.0 eps  0.39599999999954033\n",
      "episode  15200 score  -161.0 eps  0.3919999999995419\n",
      "episode  15300 score  -196.0 eps  0.38799999999954343\n",
      "episode  15400 score  -302.0 eps  0.383999999999545\n",
      "episode  15500 score  -203.0 eps  0.37999999999954653\n",
      "episode  15600 score  -162.0 eps  0.3759999999995481\n",
      "episode  15700 score  -313.0 eps  0.37199999999954964\n",
      "episode  15800 score  -270.0 eps  0.3679999999995512\n",
      "episode  15900 score  -155.0 eps  0.36399999999955274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  16000 score  -230.0 eps  0.3599999999995543\n",
      "episode  16100 score  -204.0 eps  0.35599999999955584\n",
      "episode  16200 score  -322.0 eps  0.3519999999995574\n",
      "episode  16300 score  -160.0 eps  0.34799999999955894\n",
      "episode  16400 score  -287.0 eps  0.3439999999995605\n",
      "episode  16500 score  -167.0 eps  0.33999999999956204\n",
      "episode  16600 score  -235.0 eps  0.3359999999995636\n",
      "episode  16700 score  -157.0 eps  0.33199999999956514\n",
      "episode  16800 score  -193.0 eps  0.3279999999995667\n",
      "episode  16900 score  -268.0 eps  0.32399999999956824\n",
      "episode  17000 score  -303.0 eps  0.3199999999995698\n",
      "episode  17100 score  -197.0 eps  0.31599999999957135\n",
      "episode  17200 score  -204.0 eps  0.3119999999995729\n",
      "episode  17300 score  -184.0 eps  0.30799999999957445\n",
      "episode  17400 score  -360.0 eps  0.303999999999576\n",
      "episode  17500 score  -115.0 eps  0.29999999999957755\n",
      "episode  17600 score  -169.0 eps  0.2959999999995791\n",
      "episode  17700 score  -234.0 eps  0.29199999999958065\n",
      "episode  17800 score  -241.0 eps  0.2879999999995822\n",
      "episode  17900 score  -110.0 eps  0.28399999999958375\n",
      "episode  18000 score  -182.0 eps  0.2799999999995853\n",
      "episode  18100 score  -211.0 eps  0.27599999999958685\n",
      "episode  18200 score  -251.0 eps  0.2719999999995884\n",
      "episode  18300 score  -255.0 eps  0.26799999999958996\n",
      "episode  18400 score  -204.0 eps  0.2639999999995915\n",
      "episode  18500 score  -148.0 eps  0.25999999999959306\n",
      "episode  18600 score  -164.0 eps  0.2559999999995946\n",
      "episode  18700 score  -200.0 eps  0.25199999999959616\n",
      "episode  18800 score  -166.0 eps  0.2479999999995963\n",
      "episode  18900 score  -189.0 eps  0.24399999999959507\n",
      "episode  19000 score  -161.0 eps  0.23999999999959384\n",
      "episode  19100 score  -198.0 eps  0.23599999999959262\n",
      "episode  19200 score  -259.0 eps  0.2319999999995914\n",
      "episode  19300 score  -287.0 eps  0.22799999999959017\n",
      "episode  19400 score  -166.0 eps  0.22399999999958894\n",
      "episode  19500 score  -220.0 eps  0.21999999999958772\n",
      "episode  19600 score  -239.0 eps  0.2159999999995865\n",
      "episode  19700 score  -160.0 eps  0.21199999999958527\n",
      "episode  19800 score  -211.0 eps  0.20799999999958405\n",
      "episode  19900 score  -204.0 eps  0.20399999999958282\n",
      "episode  20000 score  -283.0 eps  0.1999999999995816\n",
      "episode  20100 score  -169.0 eps  0.19599999999958037\n",
      "episode  20200 score  -145.0 eps  0.19199999999957915\n",
      "episode  20300 score  -262.0 eps  0.18799999999957792\n",
      "episode  20400 score  -154.0 eps  0.1839999999995767\n",
      "episode  20500 score  -204.0 eps  0.17999999999957547\n",
      "episode  20600 score  -115.0 eps  0.17599999999957425\n",
      "episode  20700 score  -168.0 eps  0.17199999999957302\n",
      "episode  20800 score  -152.0 eps  0.1679999999995718\n",
      "episode  20900 score  -155.0 eps  0.16399999999957057\n",
      "episode  21000 score  -192.0 eps  0.15999999999956935\n",
      "episode  21100 score  -141.0 eps  0.15599999999956812\n",
      "episode  21200 score  -153.0 eps  0.1519999999995669\n",
      "episode  21300 score  -122.0 eps  0.14799999999956567\n",
      "episode  21400 score  -196.0 eps  0.14399999999956445\n",
      "episode  21500 score  -142.0 eps  0.13999999999956322\n",
      "episode  21600 score  -158.0 eps  0.135999999999562\n",
      "episode  21700 score  -156.0 eps  0.13199999999956077\n",
      "episode  21800 score  -192.0 eps  0.12799999999955955\n",
      "episode  21900 score  -188.0 eps  0.12399999999955869\n",
      "episode  22000 score  -156.0 eps  0.11999999999955885\n",
      "episode  22100 score  -121.0 eps  0.11599999999955901\n",
      "episode  22200 score  -151.0 eps  0.11199999999955917\n",
      "episode  22300 score  -161.0 eps  0.10799999999955934\n",
      "episode  22400 score  -158.0 eps  0.1039999999995595\n",
      "episode  22500 score  -544.0 eps  0.09999999999955966\n",
      "episode  22600 score  -243.0 eps  0.09599999999955983\n",
      "episode  22700 score  -221.0 eps  0.09199999999955999\n",
      "episode  22800 score  -212.0 eps  0.08799999999956015\n",
      "episode  22900 score  -149.0 eps  0.08399999999956032\n",
      "episode  23000 score  -112.0 eps  0.07999999999956048\n",
      "episode  23100 score  -142.0 eps  0.07599999999956064\n",
      "episode  23200 score  -281.0 eps  0.0719999999995608\n",
      "episode  23300 score  -147.0 eps  0.06799999999956097\n",
      "episode  23400 score  -115.0 eps  0.06399999999956113\n",
      "episode  23500 score  -114.0 eps  0.05999999999956129\n",
      "episode  23600 score  -148.0 eps  0.055999999999561456\n",
      "episode  23700 score  -146.0 eps  0.05199999999956162\n",
      "episode  23800 score  -155.0 eps  0.04799999999956178\n",
      "episode  23900 score  -172.0 eps  0.043999999999561945\n",
      "episode  24000 score  -152.0 eps  0.03999999999956211\n",
      "episode  24100 score  -144.0 eps  0.03599999999956227\n",
      "episode  24200 score  -232.0 eps  0.031999999999562434\n",
      "episode  24300 score  -171.0 eps  0.027999999999562597\n",
      "episode  24400 score  -219.0 eps  0.02399999999956276\n",
      "episode  24500 score  -216.0 eps  0.019999999999562923\n",
      "episode  24600 score  -157.0 eps  0.015999999999563086\n",
      "episode  24700 score  -148.0 eps  0.011999999999563091\n",
      "episode  24800 score  -144.0 eps  0.01\n",
      "episode  24900 score  -145.0 eps  0.01\n",
      "episode  25000 score  -148.0 eps  0.01\n",
      "episode  25100 score  -148.0 eps  0.01\n",
      "episode  25200 score  -136.0 eps  0.01\n",
      "episode  25300 score  -152.0 eps  0.01\n",
      "episode  25400 score  -146.0 eps  0.01\n",
      "episode  25500 score  -146.0 eps  0.01\n",
      "episode  25600 score  -148.0 eps  0.01\n",
      "episode  25700 score  -143.0 eps  0.01\n",
      "episode  25800 score  -144.0 eps  0.01\n",
      "episode  25900 score  -138.0 eps  0.01\n",
      "episode  26000 score  -143.0 eps  0.01\n",
      "episode  26100 score  -144.0 eps  0.01\n",
      "episode  26200 score  -136.0 eps  0.01\n",
      "episode  26300 score  -146.0 eps  0.01\n",
      "episode  26400 score  -143.0 eps  0.01\n",
      "episode  26500 score  -139.0 eps  0.01\n",
      "episode  26600 score  -136.0 eps  0.01\n",
      "episode  26700 score  -144.0 eps  0.01\n",
      "episode  26800 score  -134.0 eps  0.01\n",
      "episode  26900 score  -142.0 eps  0.01\n",
      "episode  27000 score  -135.0 eps  0.01\n",
      "episode  27100 score  -135.0 eps  0.01\n",
      "episode  27200 score  -134.0 eps  0.01\n",
      "episode  27300 score  -142.0 eps  0.01\n",
      "episode  27400 score  -132.0 eps  0.01\n",
      "episode  27500 score  -137.0 eps  0.01\n",
      "episode  27600 score  -127.0 eps  0.01\n",
      "episode  27700 score  -141.0 eps  0.01\n",
      "episode  27800 score  -131.0 eps  0.01\n",
      "episode  27900 score  -140.0 eps  0.01\n",
      "episode  28000 score  -133.0 eps  0.01\n",
      "episode  28100 score  -136.0 eps  0.01\n",
      "episode  28200 score  -141.0 eps  0.01\n",
      "episode  28300 score  -139.0 eps  0.01\n",
      "episode  28400 score  -126.0 eps  0.01\n",
      "episode  28500 score  -138.0 eps  0.01\n",
      "episode  28600 score  -131.0 eps  0.01\n",
      "episode  28700 score  -134.0 eps  0.01\n",
      "episode  28800 score  -130.0 eps  0.01\n",
      "episode  28900 score  -227.0 eps  0.01\n",
      "episode  29000 score  -150.0 eps  0.01\n",
      "episode  29100 score  -142.0 eps  0.01\n",
      "episode  29200 score  -164.0 eps  0.01\n",
      "episode  29300 score  -163.0 eps  0.01\n",
      "episode  29400 score  -137.0 eps  0.01\n",
      "episode  29500 score  -160.0 eps  0.01\n",
      "episode  29600 score  -159.0 eps  0.01\n",
      "episode  29700 score  -149.0 eps  0.01\n",
      "episode  29800 score  -143.0 eps  0.01\n",
      "episode  29900 score  -147.0 eps  0.01\n",
      "episode  30000 score  -159.0 eps  0.01\n",
      "episode  30100 score  -156.0 eps  0.01\n",
      "episode  30200 score  -125.0 eps  0.01\n",
      "episode  30300 score  -156.0 eps  0.01\n",
      "episode  30400 score  -155.0 eps  0.01\n",
      "episode  30500 score  -141.0 eps  0.01\n",
      "episode  30600 score  -134.0 eps  0.01\n",
      "episode  30700 score  -163.0 eps  0.01\n",
      "episode  30800 score  -107.0 eps  0.01\n",
      "episode  30900 score  -230.0 eps  0.01\n",
      "episode  31000 score  -231.0 eps  0.01\n",
      "episode  31100 score  -145.0 eps  0.01\n",
      "episode  31200 score  -137.0 eps  0.01\n",
      "episode  31300 score  -93.0 eps  0.01\n",
      "episode  31400 score  -135.0 eps  0.01\n",
      "episode  31500 score  -137.0 eps  0.01\n",
      "episode  31600 score  -120.0 eps  0.01\n",
      "episode  31700 score  -148.0 eps  0.01\n",
      "episode  31800 score  -117.0 eps  0.01\n",
      "episode  31900 score  -147.0 eps  0.01\n",
      "episode  32000 score  -141.0 eps  0.01\n",
      "episode  32100 score  -145.0 eps  0.01\n",
      "episode  32200 score  -150.0 eps  0.01\n",
      "episode  32300 score  -151.0 eps  0.01\n",
      "episode  32400 score  -147.0 eps  0.01\n",
      "episode  32500 score  -147.0 eps  0.01\n",
      "episode  32600 score  -149.0 eps  0.01\n",
      "episode  32700 score  -139.0 eps  0.01\n",
      "episode  32800 score  -148.0 eps  0.01\n",
      "episode  32900 score  -146.0 eps  0.01\n",
      "episode  33000 score  -161.0 eps  0.01\n",
      "episode  33100 score  -152.0 eps  0.01\n",
      "episode  33200 score  -218.0 eps  0.01\n",
      "episode  33300 score  -137.0 eps  0.01\n",
      "episode  33400 score  -145.0 eps  0.01\n",
      "episode  33500 score  -132.0 eps  0.01\n",
      "episode  33600 score  -133.0 eps  0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  33700 score  -161.0 eps  0.01\n",
      "episode  33800 score  -149.0 eps  0.01\n"
     ]
    }
   ],
   "source": [
    "#Führt das eigentliche Spielen und Lernen aus\n",
    "\n",
    "score = 0 #Belohnung eines einzelnen Spieldurchlaufes\n",
    "total_rewards = np.zeros(n_games) #Belohnung aller Durchläufe\n",
    "\n",
    "for i in range(n_games):\n",
    "    done = False\n",
    "    obs = env.reset() #Beobachtung zum Startzeitpunkt\n",
    "    if i % 100 == 0 and i>0:\n",
    "        print('episode ', i, 'score ', score, 'eps ', eps)\n",
    "    score = 0\n",
    "    while not done:\n",
    "        #Epsilon-Greedy-Algorithmus\n",
    "        action = get_action(Q, obs)\n",
    "        new_obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "        new_action = get_action(Q, new_obs)\n",
    "        updateQ_SARSA(obs, action, reward, new_obs, new_action)\n",
    "        obs = new_obs\n",
    "    total_rewards[i] = score\n",
    "    if eps > 0.01:\n",
    "        eps = eps - 2/n_games\n",
    "    else:\n",
    "        eps = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveQ()\n",
    "show_result()\n",
    "mean_rewards = np.zeros(n_games)\n",
    "for r in range(n_games):\n",
    "    mean_rewards[r] = np.mean(total_rewards[max(0, r-50):(r+1)])\n",
    "plt.plot(mean_rewards)\n",
    "plt.savefig('mountaincar.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
